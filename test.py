import requests
import json
import os
import time
from dotenv import load_dotenv

# T·∫£i c·∫•u h√¨nh t·ª´ file .env
load_dotenv()

class PancakeScanner:
    def __init__(self):
        self.user_token = os.getenv("PANCAKE_USER_TOKEN")
        self.api_v1 = "https://pages.fm/api/v1"
        self.public_v1 = "https://pages.fm/api/public_api/v1"
        self.public_v2 = "https://pages.fm/api/public_api/v2"
        
        if not self.user_token:
            raise ValueError("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh PANCAKE_USER_TOKEN trong file .env")

    def get_pages(self):
        """L·∫•y danh s√°ch to√†n b·ªô c√°c trang"""
        resp = requests.get(f"{self.api_v1}/pages", params={"access_token": self.user_token})
        if resp.status_code != 200:
            return []
        data = resp.json().get("categorized", {})
        return data.get("activated", []) + data.get("inactivated", [])

    def get_page_token(self, page_id):
        """T·∫°o Page Access Token"""
        url = f"{self.api_v1}/pages/{page_id}/generate_page_access_token"
        resp = requests.post(url, params={"page_id": page_id, "access_token": self.user_token})
        return resp.json().get("page_access_token") if resp.status_code == 200 else None

    def get_tag_map(self, page_id, page_token):
        """L·∫•y danh s√°ch tag ƒë·ªÉ ƒë·ªëi chi·∫øu ID v√† Text"""
        tag_map = {}
        url = f"{self.public_v1}/pages/{page_id}/tags"
        resp = requests.get(url, params={"page_access_token": page_token})
        if resp.status_code == 200:
            for t in resp.json().get("tags", []):
                tag_map[str(t.get("id"))] = t.get("text")
        return tag_map

    def fetch_all_conversations(self, page_id, page_token):
        """
        L·∫•y TO√ÄN B·ªò h·ªôi tho·∫°i b·∫±ng c√°ch l·∫∑p qua last_conversation_id
        (GI·ªÆ NGUY√äN LOGIC C≈®)
        """
        all_convs = []
        last_id = None
        
        while True:
            params = {
                "page_access_token": page_token,
                "type": "INBOX"
            }
            if last_id:
                params["last_conversation_id"] = last_id  # S·ª≠ d·ª•ng ƒë·ªÉ l·∫•y 60 b·∫£n ghi ti·∫øp theo

            url = f"{self.public_v2}/pages/{page_id}/conversations"
            resp = requests.get(url, params=params)
            
            if resp.status_code != 200:
                break
                
            data = resp.json().get("conversations", [])
            if not data:
                break
            
            all_convs.extend(data)
            
            # L·∫•y ID c·ªßa h·ªôi tho·∫°i cu·ªëi c√πng trong danh s√°ch ƒë·ªÉ l√†m m·ªëc cho l·∫ßn g·ªçi t·ªõi
            last_id = data[-1].get("id")
            
            # T·∫°m ngh·ªâ ƒë·ªÉ tr√°nh b·ªã gi·ªõi h·∫°n rate limit n·∫øu d·ªØ li·ªáu qu√° l·ªõn
            time.sleep(0.2) 
            
            # N·∫øu tr·∫£ v·ªÅ √≠t h∆°n 60, nghƒ©a l√† ƒë√£ h·∫øt d·ªØ li·ªáu
            if len(data) < 60:
                break
                
        return all_convs


def main():
    scanner = PancakeScanner()
    
    result = {
        "summary": {
            "total_pages": 0,
            "total_conversations_scanned": 0,
            "total_leads_found": 0
        },
        "details": []
    }

    print("üöÄ B·∫Øt ƒë·∫ßu qu√©t to√†n b·ªô d·ªØ li·ªáu t·ª´ Pancake...")
    pages = scanner.get_pages()
    result["summary"]["total_pages"] = len(pages)

    for page in pages:
        p_id = str(page.get("id"))
        p_name = page.get("name")
        print(f"--- ƒêang x·ª≠ l√Ω Page: {p_name} ({p_id}) ---")

        token = scanner.get_page_token(p_id)
        if not token:
            print(f"  ‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c token cho {p_name}")
            continue

        tag_map = scanner.get_tag_map(p_id, token)
        conversations = scanner.fetch_all_conversations(p_id, token)
        
        page_conv_count = len(conversations)
        page_lead_count = 0
        result["summary"]["total_conversations_scanned"] += page_conv_count

        for conv in conversations:
            conv_tags = conv.get("tags", [])

            # ===== LOGIC FILTER TAG GI·ªêNG pancake.py (support c·∫£ dict v√† id) =====
            is_lead = False
            sector = None
            status = "Kh√°ch M·ªõi"

            processed_tags = []

            for item in conv_tags:
                # Pancake v2 c√≥ th·ªÉ tr·∫£ tags d·∫°ng dict {"id":..,"text":..} ho·∫∑c ch·ªâ id
                if isinstance(item, dict):
                    tag_text = item.get("text")
                else:
                    tag_text = tag_map.get(str(item))

                if not tag_text:
                    continue

                processed_tags.append(tag_text)

                # TAG NH√ìM 1 ‚Üí SECTOR
                if tag_text.startswith("1-"):
                    is_lead = True
                    if "Express" in tag_text:
                        sector = "Express"
                    elif "Warehouse" in tag_text:
                        sector = "Warehouse"
                    else:
                        sector = "Pod_Drop"

                # TAG NH√ìM 2 ‚Üí STATUS
                if tag_text.startswith("2-"):
                    raw = tag_text.split("-", 1)[-1].strip().lower()
                    if raw == "kh√°ch ch·ªët":
                        status = "Kh√°ch h√†ng ti·ªÅm nƒÉng"
                    elif raw == "kh√°ch vip":
                        status = "Kh√°ch Vip"

            # Gi·ªØ ƒë√∫ng rule: ch·ªâ coi l√† lead khi c√≥ tag 1-*
            if not is_lead:
                continue

            page_lead_count += 1
            customers = conv.get("customers", [])
            customer_name = customers[0].get("name") if customers else "N/A"

            result["details"].append({
                "page_name": p_name,
                "page_id": p_id,
                "customer_name": customer_name,
                "conversation_id": conv.get("id"),
                "sector": sector,
                "status": status,
                "tags": processed_tags,
                "updated_at": conv.get("updated_at")
            })

        result["summary"]["total_leads_found"] += page_lead_count
        print(f"  ‚úÖ ƒê√£ qu√©t {page_conv_count} h·ªôi tho·∫°i. T√¨m th·∫•y {page_lead_count} leads.")

    # Xu·∫•t k·∫øt qu·∫£
    output_file = "full_scan_result.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=4, ensure_ascii=False)

    print("\n" + "="*30)
    print("HO√ÄN TH√ÄNH QU√âT D·ªÆ LI·ªÜU")
    print(f"T·ªïng s·ªë Page: {result['summary']['total_pages']}")
    print(f"T·ªïng s·ªë h·ªôi tho·∫°i ƒë√£ ki·ªÉm tra: {result['summary']['total_conversations_scanned']}")
    print(f"T·ªïng s·ªë Lead th·ªèa ƒëi·ªÅu ki·ªán (1-): {result['summary']['total_leads_found']}")
    print(f"D·ªØ li·ªáu chi ti·∫øt ƒë√£ l∆∞u t·∫°i: {output_file}")


if __name__ == "__main__":
    main()
